{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "diagnostic-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from scipy.stats import mode as mode\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.metrics import mean_squared_error,classification_report\n",
    "from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-concrete",
   "metadata": {},
   "source": [
    "Predicting the sex of abolone using various and weight measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "overhead-information",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   len         4177 non-null   float64\n",
      " 1   diam        4177 non-null   float64\n",
      " 2   ht          4177 non-null   float64\n",
      " 3   whole_wt    4177 non-null   float64\n",
      " 4   shucked_wt  4177 non-null   float64\n",
      " 5   viscera_wt  4177 non-null   float64\n",
      " 6   shell_wt    4177 non-null   float64\n",
      " 7   rings       4177 non-null   int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 261.2 KB\n"
     ]
    }
   ],
   "source": [
    "X =  pd.read_csv('abalone.data',names=['sex','len','diam','ht','whole_wt','shucked_wt',\n",
    "                                       'viscera_wt','shell_wt','rings'])\n",
    "y = X.pop('sex')\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "turkish-receptor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'F', 'I'], dtype=object)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-tennessee",
   "metadata": {},
   "source": [
    "> Male, female, imature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "killing-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-screen",
   "metadata": {},
   "source": [
    "## Data splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "reverse-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-research",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "higher-paste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy:\n",
      "\t0.6794380587484036\n",
      "Test Set Accuracy:\n",
      "\t0.5406698564593302\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_predict = knn.predict(X_test)\n",
    "y_train_predict = knn.predict(X_train)\n",
    "\n",
    "\n",
    "print(f'Training Set Accuracy:\\n\\t{overall_accuracy(y_train,y_train_predict)}')\n",
    "print(f'Test Set Accuracy:\\n\\t{overall_accuracy(y_test,y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "sharing-inspector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.60      0.65      0.62       970\n",
      "           I       0.76      0.81      0.79      1008\n",
      "           M       0.68      0.59      0.63      1154\n",
      "\n",
      "    accuracy                           0.68      3132\n",
      "   macro avg       0.68      0.68      0.68      3132\n",
      "weighted avg       0.68      0.68      0.68      3132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,y_train_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-keeping",
   "metadata": {},
   "source": [
    "## Hyperparameter turning (choose whatever approach your like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "stretch-bikini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 200 candidates, totalling 1600 fits\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid = {'n_neighbors':[n for n in range(1,51)],\n",
    "        'weights':['uniform','distance'],\n",
    "        'p':[1,2]}\n",
    "\n",
    "GRID = GridSearchCV(knn,grid,cv=8,verbose=1).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "personalized-sampling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 43, 'p': 1, 'weights': 'distance'}"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRID.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-tennis",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "angry-radius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy:\n",
      "\t1.0\n",
      "Test Set Accuracy:\n",
      "\t0.5492822966507177\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.47      0.36      0.41       337\n",
      "           I       0.69      0.81      0.75       334\n",
      "           M       0.46      0.48      0.47       374\n",
      "\n",
      "    accuracy                           0.55      1045\n",
      "   macro avg       0.54      0.55      0.54      1045\n",
      "weighted avg       0.54      0.55      0.54      1045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=43,\n",
    "                           weights='distance',\n",
    "                           p=1)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_predict = knn.predict(X_test)\n",
    "y_train_predict = knn.predict(X_train)\n",
    "\n",
    "\n",
    "print(f'Training Set Accuracy:\\n\\t{overall_accuracy(y_train,y_train_predict)}')\n",
    "print(f'Test Set Accuracy:\\n\\t{overall_accuracy(y_test,y_predict)}\\n')\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-ratio",
   "metadata": {},
   "source": [
    "The accuracy dropped a significantly from the test set to the training set, indicating that there was overfitting of the model is an issue. This is especially notable with the grid search model, which had 100% accuracy on the training set, suggesting the model essentially memorized the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-tunnel",
   "metadata": {},
   "source": [
    "## Compare Results with random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "quiet-sauce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model\n",
      "\n",
      "Training Set Accuracy:\n",
      "\t1.0\n",
      "Test Set Accuracy:\n",
      "\t0.5260930888575458\n",
      "\n",
      "Fitting 8 folds for each of 294 candidates, totalling 2352 fits\n",
      "{'max_depth': 4, 'max_features': 7, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "X =  pd.read_csv('abalone.data',names=['sex','len','diam','ht','whole_wt','shucked_wt',\n",
    "                                       'viscera_wt','shell_wt','rings'])\n",
    "\n",
    "X = X[X.sex!='I']\n",
    "y = X.pop('sex')\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y)\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "forest.fit(X_train,y_train)\n",
    "\n",
    "y_predict = forest.predict(X_test)\n",
    "y_train_predict = forest.predict(X_train)\n",
    "\n",
    "print('Base model\\n')\n",
    "print(f'Training Set Accuracy:\\n\\t{overall_accuracy(y_train,y_train_predict)}')\n",
    "print(f'Test Set Accuracy:\\n\\t{overall_accuracy(y_test,y_predict)}\\n')\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "grid = {'n_estimators':[50,100,150],\n",
    "        'max_depth':[d for d in range(1,15)],\n",
    "        'max_features':[f for f in range(1,len(X_train.columns))]}\n",
    "\n",
    "GRID = GridSearchCV(forest,grid,cv=8,verbose=1).fit(X_train,y_train)\n",
    "\n",
    "print(GRID.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "figured-ensemble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy:\n",
      "\t0.6039510818438382\n",
      "Test Set Accuracy:\n",
      "\t0.5669957686882934\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.55      0.22      0.32       321\n",
      "           M       0.57      0.85      0.68       388\n",
      "\n",
      "    accuracy                           0.57       709\n",
      "   macro avg       0.56      0.54      0.50       709\n",
      "weighted avg       0.56      0.57      0.52       709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=150,\n",
    "                                max_depth=4,\n",
    "                                max_features=7)\n",
    "\n",
    "forest.fit(X_train,y_train)\n",
    "\n",
    "y_predict = forest.predict(X_test)\n",
    "y_train_predict = forest.predict(X_train)\n",
    "\n",
    "print(f'Training Set Accuracy:\\n\\t{overall_accuracy(y_train,y_train_predict)}')\n",
    "print(f'Test Set Accuracy:\\n\\t{overall_accuracy(y_test,y_predict)}\\n')\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-intersection",
   "metadata": {},
   "source": [
    "The random forest model performed better and had less issues with overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-marble",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
